# awesome-dLLM-resources
Frequently updated list of dLLM (Diffusion Large Language Models) papers, models, and other resources.

Maintained by Suhas Pai and Xiaojun Ren

## Models
- **Large Language Diffusion Models** — *February 14* <i><a href="https://arxiv.org/abs/2502.09992" target="_blank">arXiv</a></i>
- **LLaDA 1.5: Variance-Reduced Preference Optimization for Large Language Diffusion Models** — *May 25* <i><a href="https://arxiv.org/abs/2505.19223" target="_blank">arXiv</a></i>
- **LLaDA-MoE: A Sparse MoE Diffusion Language Model** - *September 25* <i><a href="https://arxiv.org/abs/2509.24389" target="_blank">arXiv</a></i>
- **UltraLLaDA: Scaling the Context Length to 128K for Diffusion Large Language Models** — *October 12* <i><a href="https://arxiv.org/abs/2510.10481" target="_blank">arXiv</a></i>
- **Soft-Masked Diffusion Language Models** - *October 20* <i><a href="https://arxiv.org/abs/2510.17206" target ="_blank">arXiv</a></i>

## Reasoning in dLLMs
- **Improving Reasoning for Diffusion Language Models via Group Diffusion Policy Optimization** — *October 9* <i><a href="https://arxiv.org/abs/2510.08554" target="_blank">arXiv</a></i>
- **DiFFPO: Training Diffusion LLMs to Reason Fast and Furious via Reinforcement Learning** — *October 2* <i><a href="https://arxiv.org/abs/2510.02212" target="_blank">arXiv</a></i>
- **RFG: Test-Time Scaling for Diffusion Large Language Model Reasoning with Reward-Free Guidance** — *September 29* <i><a href="https://arxiv.org/abs/2509.25604" target="_blank">arXiv</a></i>

## Scaling laws
- **Diffusion Language Models are Super Data Learners** — *October 1* <i><a href="https://jinjieni.github.io/dlms-are-super-data-learners/resources/pdf/Diffusion_Language_Models_are_Super_Data_Learners.pdf" target="_blank">Github</a></i>
- **Diffusion Beats Autoregressive in Data-Constrained Settings** — *July 21* <i><a href="https://arxiv.org/abs/2507.15857" target="_blank">arXiv</a></i>

## Architectures
- **Syntax-Guided Diffusion Language Models with User-Integrated Personalization** — *October 2* <i><a href="https://arxiv.org/abs/2510.01028" target="_blank">arXiv</a></i>
- **Revolutionizing reinforcement learning framework for diffusion large language models** — *September 8* <i><a href="https://arxiv.org/abs/2509.06949" target="_blank">arXiv</a></i>
- **CoDA: Coding LM via Diffusion Adaptation** — *September 27* <i><a href="https://arxiv.org/abs/2510.03270" target="_blank">arXiv</a></i>

## Finetuning
- **WeFT: Weighted Entropy-driven Fine-Tuning for dLLMs** - *September 25* <i><a href="https://arxiv.org/abs/2509.20863" target="_ blank">arXiv</a></i>

## Inference
- **Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative Decoding** — *September 22* <i><a href="https://arxiv.org/abs/2509.18085" target="_blank">arXiv</a></i>
- **Thinking Inside the Mask: In-Place Prompting in Diffusion LLMs** — *August 14* <i><a href="https://arxiv.org/abs/2508.10736" target="_blank">arXiv</a></i>
- **Dllmquant: Quantizing diffusion-based large language models** — *August 14* <i><a href="https://arxiv.org/abs/2508.14090" target="_blank">arXiv</a></i>

## Safety
- **Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety Flaws in Diffusion-Based Text Generation** — *July 25* <i><a href="https://arxiv.org/abs/2507.19227" target="_blank">arXiv</a></i>

## Applications
- **Discovering Mathematical Equations with Diffusion Language Model** — *September 16* <i><a href="https://arxiv.org/abs/2509.13136" target="_blank">arXiv</a></i>

## Survey
- **A Survey on Diffusion Language Models** — *August 14* <i><a href="https://arxiv.org/abs/2508.10875" target="_blank">arXiv</a></i>
- **Diffusion-based Large Language Models Survey** — *August 26* <i><a href="https://www.techrxiv.org/users/952417/articles/1321784-diffusion-based-large-language-models-survey" target="_blank">TechRxiv</a></i>
